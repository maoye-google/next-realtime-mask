from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
# import socketio # python-socketio is for Socket.IO server, FastAPI uses its own WebSocket
import os
import json
import uuid
from datetime import datetime
from kafka import KafkaProducer, KafkaConsumer
from pymongo import MongoClient
from pymongo.errors import ConnectionFailure
import threading
import logging
import base64
import cv2
import numpy as np

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

KAFKA_BOOTSTRAP_SERVERS = os.getenv('KAFKA_BOOTSTRAP_SERVERS', 'localhost:9092')
MONGO_URI = os.getenv('MONGO_URI', 'mongodb://localhost:27017/')
SNAPSHOT_REQUESTS_TOPIC = 'snapshot-requests'
PROCESSING_RESULTS_TOPIC = 'processing-results'

# Global state (use with caution in production, consider Redis or other shared state for scalability)
active_websockets = {} # session_id: WebSocket
tracking_sessions = {} # session_id: {"tracker": cv2.Tracker, "mask_format": "grey_out/border_highlight", "initial_mask_coords": [], "last_known_bbox": None}
image_id_to_session_id = {} # image_id: session_id

app = FastAPI()

# CORS (Cross-Origin Resource Sharing)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], # Allows all origins for development
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Kafka Producer
try:
    producer = KafkaProducer(
        bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
        value_serializer=lambda v: json.dumps(v).encode('utf-8')
    )
except Exception as e:
    logger.error(f"Failed to connect to Kafka producer: {e}")
    producer = None # Application should ideally not start or indicate critical error

# MongoDB Client
try:
    mongo_client = MongoClient(MONGO_URI)
    db = mongo_client.realtime_mask_db # Database name
    processing_results_collection = db.processing_results
    mongo_client.admin.command('ping') # Verify connection
except Exception as e:
    logger.error(f"Failed to connect to MongoDB: {e}")
    processing_results_collection = None


class SnapshotRequest(BaseModel):
    image: str # base64_string
    prompt: str
    sessionId: str # uuid, should be generated by frontend and passed
    maskFormat: str # "grey_out" or "border_highlight"

@app.post("/api/detect")
async def detect_object(request: SnapshotRequest):
    if not producer:
        raise HTTPException(status_code=503, detail="Kafka producer not available")
    
    image_id = str(uuid.uuid4())
    image_id_to_session_id[image_id] = request.sessionId # Link image_id to session_id

    # Store maskFormat for the session, to be used when tracking starts
    if request.sessionId not in tracking_sessions:
        tracking_sessions[request.sessionId] = {}
    tracking_sessions[request.sessionId]['mask_format'] = request.maskFormat

    message = {
        "imageId": image_id,
        "imageData": request.image,
        "prompt": request.prompt,
        "requestTimestamp": datetime.utcnow().isoformat()
    }
    producer.send(SNAPSHOT_REQUESTS_TOPIC, value=message)
    logger.info(f"Sent snapshot request to Kafka: {image_id} for session: {request.sessionId}")
    return {"message": "Snapshot received and sent for processing", "imageId": image_id}

@app.delete("/api/results")
async def delete_all_results():
    if not processing_results_collection:
        raise HTTPException(status_code=503, detail="MongoDB not available")
    try:
        result = processing_results_collection.delete_many({})
        logger.info(f"Deleted {result.deleted_count} documents from processing_results.")
        # Also clear any active tracking state if desired
        # tracking_sessions.clear()
        # image_id_to_session_id.clear()
        return {"message": f"Successfully deleted {result.deleted_count} results."}
    except Exception as e:
        logger.error(f"Error deleting results from MongoDB: {e}")
        raise HTTPException(status_code=500, detail="Failed to delete results")

def apply_mask_to_frame(frame, bbox, mask_coords, mask_format):
    if mask_format == "grey_out":
        if bbox:
            x, y, w, h = [int(v) for v in bbox]
            sub_img = frame[y:y+h, x:x+w]
            grey_rect = np.zeros(sub_img.shape, dtype=np.uint8)
            # For simplicity, make it semi-transparent black
            # A true grey out might involve blending
            res = cv2.addWeighted(sub_img, 0.5, grey_rect, 0.5, 1.0)
            frame[y:y+h, x:x+w] = res
    elif mask_format == "border_highlight":
        if mask_coords: # Use original segmentation mask for border
            pts = np.array(mask_coords, np.int32)
            pts = pts.reshape((-1, 1, 2))
            cv2.polylines(frame, [pts], isClosed=True, color=(0, 255, 0), thickness=2)
        elif bbox: # Fallback to bounding box if precise mask_coords not available for tracking
            x, y, w, h = [int(v) for v in bbox]
            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
    return frame

def decode_image(base64_string):
    img_bytes = base64.b64decode(base64_string.split(',')[-1]) # Handle "data:image/jpeg;base64," prefix
    img_array = np.frombuffer(img_bytes, dtype=np.uint8)
    frame = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
    return frame

def encode_image(frame):
    _, buffer = cv2.imencode('.jpg', frame)
    base64_string = base64.b64encode(buffer).decode('utf-8')
    return f"data:image/jpeg;base64,{base64_string}"

@app.websocket("/ws/{session_id}")
async def websocket_endpoint(websocket: WebSocket, session_id: str):
    await websocket.accept()
    active_websockets[session_id] = websocket
    logger.info(f"WebSocket connection established for session: {session_id}")
    try:
        while True:
            payload_str = await websocket.receive_text()
            payload = json.loads(payload_str)
            event_type = payload.get("event")

            if event_type == "stream_frame":
                frame_data_b64 = payload.get("image")
                frame_timestamp_str = payload.get("timestamp")
                
                if not frame_data_b64 or not frame_timestamp_str:
                    logger.warning(f"Missing image or timestamp in stream_frame for session {session_id}")
                    continue

                frame_timestamp = datetime.fromisoformat(frame_timestamp_str.replace("Z", "+00:00"))
                original_frame = decode_image(frame_data_b64)
                processed_frame_np = original_frame.copy()

                session_state = tracking_sessions.get(session_id, {})

                # Initialize tracker if pending and we have the initial data
                if session_state.get("status") == "pending_tracker_init" and not session_state.get("tracker"):
                    initial_bbox = session_state.get("initial_bbox")
                    initial_snapshot_b64 = session_state.get("initial_snapshot_data")

                    if initial_bbox and initial_snapshot_b64:
                        logger.info(f"Initializing tracker for session {session_id} with bbox {initial_bbox}")
                        initial_snapshot_frame = decode_image(initial_snapshot_b64)
                        if initial_snapshot_frame is not None:
                            tracker = cv2.TrackerCSRT_create() # Or from session_state["tracker_type"]
                            tracker.init(initial_snapshot_frame, tuple(initial_bbox))
                            session_state["tracker"] = tracker
                            session_state["status"] = "tracking" # Update status
                            logger.info(f"Tracker initialized successfully for session {session_id}. Sending 'tracking_started'.")
                            await websocket.send_json({"event": "tracking_started", "imageId": session_state.get("last_processed_image_id", "")})
                        else:
                            logger.error(f"Failed to decode initial snapshot for tracker init, session {session_id}")
                            session_state["status"] = "error_tracker_init" # Mark error
                    else:
                        logger.warning(f"Missing initial_bbox or initial_snapshot_data for tracker init, session {session_id}")

                if session_state.get("status") == "tracking" and session_state.get("tracker"):
                    tracker = session_state["tracker"]
                    mask_format = session_state.get("mask_format", "grey_out")
                    initial_mask_coords = session_state.get("initial_mask_coords", [])

                    success, bbox = tracker.update(original_frame)
                    if success:
                        session_state["last_known_bbox"] = bbox
                        # For border_highlight, ideally, we'd re-segment or use the initial detailed mask
                        # and transform it. For simplicity, we use bbox for border if mask_coords are not updated.
                        # If using mask_coords, they should be relative to the tracked bbox or re-calculated.
                        # Here, we'll use initial_mask_coords if available for border, otherwise bbox.
                        current_mask_coords_for_border = initial_mask_coords if mask_format == "border_highlight" and initial_mask_coords else None
                        processed_frame_np = apply_mask_to_frame(processed_frame_np, bbox, current_mask_coords_for_border, mask_format)
                    else:
                        logger.info(f"Tracking lost for session {session_id}")
                        # Optionally, re-initialize detection or use last known bbox for a few frames
                        if session_state.get("last_known_bbox"):
                           processed_frame_np = apply_mask_to_frame(processed_frame_np, session_state["last_known_bbox"], None, mask_format)
                        # Consider setting status to 'lost' or 're-detect'
                        # session_state["status"] = "lost"

                processed_image_b64 = encode_image(processed_frame_np)
                delay = (datetime.utcnow() - frame_timestamp).total_seconds()

                await websocket.send_json({
                    "event": "processed_frame",
                    "processedImage": processed_image_b64,
                    "controlImage": frame_data_b64, # Send back the original base64
                    "delay": delay,
                    "timestamp": datetime.utcnow().isoformat()
                })
            else:
                logger.info(f"Received unknown WebSocket event '{event_type}' from session {session_id}: {payload}")

    except WebSocketDisconnect:
        logger.info(f"WebSocket connection closed for session: {session_id}")
    except Exception as e:
        logger.error(f"WebSocket error for session {session_id}: {e}")
    finally:
        if session_id in active_websockets:
            del active_websockets[session_id]
        if session_id in tracking_sessions: # Clean up tracking state
            # del tracking_sessions[session_id] # Or keep for re-connection?
            pass

@app.get("/")
async def root():
    return {"message": "Real-time Masking Backend is running"}

def kafka_consumer_thread_func():
    logger.info("Kafka consumer thread started for 'processing-results' topic.")
    try:
        consumer = KafkaConsumer(
            PROCESSING_RESULTS_TOPIC,
            bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
            auto_offset_reset='earliest',
            group_id='backend-processing-results-group',
            value_deserializer=lambda m: json.loads(m.decode('utf-8'))
        )
    except Exception as e:
        logger.error(f"Failed to connect Kafka consumer for {PROCESSING_RESULTS_TOPIC}: {e}")
        return

    for message in consumer:
        try:
            data = message.value
            logger.info(f"Received from '{PROCESSING_RESULTS_TOPIC}': {data}")

            if processing_results_collection is not None:
                # Add createdAt timestamp for MongoDB
                data["createdAt"] = datetime.utcnow()
                # TODO: Calculate detectionLatencyMs if not provided by worker
                processing_results_collection.insert_one(data)
                logger.info(f"Stored result for imageId {data.get('imageId')} in MongoDB.")

            image_id = data.get("imageId")
            session_id = image_id_to_session_id.get(image_id)


            if session_id and session_id in active_websockets:
                websocket = active_websockets[session_id]
                if data.get("isFound") and data.get("maskCoordinates"):
                    mask_coords = data["maskCoordinates"]
                    # Initialize tracker (e.g., CSRT)
                    # For CSRT, we need an initial bounding box from the mask_coordinates
                    if mask_coords:
                        np_mask_coords = np.array(mask_coords)
                        x, y, w, h = cv2.boundingRect(np_mask_coords)
                        
                        tracker = cv2.TrackerCSRT_create() # Or another tracker
                        # The tracker needs an initial frame. This is a challenge as we don't have it here.
                        # The plan implies frontend sends snapshot, then switches to stream.
                        # We need the snapshot frame to init the tracker.
                        # This requires a more complex state management or sending the initial frame again.
                        # For now, we'll set it up, but tracker init will fail without a frame.
                        # This part needs refinement in the overall flow.
                        # A possible solution: Store the initial snapshot frame in `tracking_sessions` when /api/detect is called.

                        tracking_sessions[session_id]["tracker_type"] = "CSRT" # Store type for re-creation if needed
                        tracking_sessions[session_id]["initial_bbox"] = (x,y,w,h) # Store bbox
                        tracking_sessions[session_id]["initial_mask_coords"] = mask_coords
                        
                        # The tracker must be initialized with a frame.
                        # This is a critical point: the consumer doesn't have the frame.
                        # The /api/detect endpoint should store the initial frame if it's needed here.
                        # For now, we'll just notify the client. The client then starts streaming,
                        # and the first streamed frame could be used for tracker.init().
                        # This means the tracker is initialized in the WebSocket handler.

                        logger.info(f"Notifying session {session_id} that tracking can start for imageId {image_id}")
                        # Ensure this is an async call if websocket.send_json is.
                        # Since this is in a thread, direct await is not possible.
                        # Need to use asyncio.run_coroutine_threadsafe or similar if FastAPI runs in an event loop.
                        # For simplicity, assuming direct send works or using a queue to pass to event loop.
                        # This is a common challenge with threads and asyncio.
                        # A simpler way for now: client starts streaming, and on first frame, backend inits tracker.
                        
                        # Let's adjust: the websocket handler will initialize the tracker on the first frame
                        # after 'tracking_started' is set.
                        tracking_sessions[session_id]["status"] = "pending_tracker_init"

                        # This send_json needs to be thread-safe or run in the event loop
                        # For now, let's assume a simplified direct call (might need `asyncio.run` or similar)
                        # This will likely fail if not handled with asyncio event loop correctly.
                        # A better way: use a queue to pass messages from this thread to the main asyncio loop.
                        # For now, we'll log and the client side will need to handle this.
                        # The websocket.send_json needs to be called from an async context.
                        # This is a placeholder for how to signal the client.
                        # A robust solution involves `asyncio.run_coroutine_threadsafe`.
                        # For now, let's just update the state. The client will poll or the websocket will check.
                        # The 'tracking_started' event is better sent from an async context.
                        # Let's assume the websocket handler checks this status.

                        # To properly send to websocket from thread:
                        # loop = asyncio.get_event_loop()
                        # asyncio.run_coroutine_threadsafe(websocket.send_json({"event": "tracking_started", "imageId": image_id}), loop)
                        logger.info(f"Sent (conceptually) 'tracking_started' to session {session_id} for imageId {image_id}")

                elif data.get("error"):
                    logger.error(f"Processing error for imageId {image_id}: {data.get('error')}")
                    # Notify client of error?
            if image_id in image_id_to_session_id: # Clean up mapping
                del image_id_to_session_id[image_id]

        except json.JSONDecodeError:
            logger.error(f"Failed to decode Kafka message: {message.value}")
        except Exception as e:
            logger.error(f"Error processing Kafka message in backend: {e}, message: {message.value}")


@app.on_event("startup")
async def startup_event():
    # Start Kafka consumer in a background thread
    thread = threading.Thread(target=kafka_consumer_thread_func, daemon=True)
    thread.start()
    logger.info("Backend application startup complete. Kafka consumer thread initiated.")

logger.info("Backend application started.")